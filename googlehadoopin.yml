- hosts: google-*
  become: yes
  pre_tasks:
   - name: Run the equivalent of "apt-get update" as a separate step
     apt:
       update_cache: yes

   - name: Installing java apt
     apt:
       name: openjdk-8-jdk-headless
       state: present   
   - name: Get apache hadoop
     get_url: 
       url: https://archive.apache.org/dist/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz
       dest: /home/suhailmsu21

   - name: Extract  hadoop
     ansible.builtin.unarchive:
       src: /home/suhailmsu21/hadoop-3.2.2.tar.gz
       dest: /home/suhailmsu21
       remote_src: True
       owner: suhailmsu21

   - name: removing existing hadoop file
     raw: rm -r -f /home/suhailmsu21/hadoop
   - name: Editing bashrc
     ansible.builtin.blockinfile:
       dest: .bashrc
       insertafter: EOF
       block: |
         export HADOOP_HOME=/usr/local/hadoop
         export PATH=$PATH:$HADOOP_HOME/bin
         export PATH=$PATH:$HADOOP_HOME/sbin
         export HADOOP_MAPRED_HOME=${HADOOP_HOME}
         export HADOOP_COMMON_HOME=${HADOOP_HOME}
         export HADOOP_HDFS_HOME=${HADOOP_HOME}
         export YARN_HOME=${HADOOP_HOME}
         export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
         export SPARK_HOME=/usr/local/spark
         export PYSPARK_PYTHON=python3
         export PATH=$PATH:$SPARK_HOME/bin
         export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native:$LD_LIBRARY_PATH
         export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/build:$PYTHONPATH
         export ZOO_HOME=/usr/local/zookeeper
         export PATH=$ZOO_HOME/bin:$PATH
         export MASTER_DIR=/usr/local/apache-drill
         export DRILL_SITE=/etc/drill-site
         export DRILL_NAME=apache-drill
         export DRILL_HOME=/usr/local/$DRILL_NAME
         function sparknotebook()
          {
          export PYSPARK_PYTHON=python3
          export SPARK_HOME=/usr/local/spark
          export PYSPARK_DRIVER_PYTHON=jupyter
          export PYSPARK_DRIVER_PYTHON_OPTS="notebook"
          $SPARK_HOME/bin/pyspark --packages databricks:spark-deep-learning:1.5.0-spark2.4-s_2.11
          }
       backup: yes
       owner: suhailmsu21

   - name: changing directory from hadoop-3.2.2 to hadoop
     raw: mv hadoop-3.2.2 hadoop/

   - name: Change permission 
     ansible.builtin.file:
       path: /home/suhailmsu21/hadoop
       state: directory
       mode: '0755'
       owner: suhailmsu21
   - name: Make dir hdfstmp
     ansible.builtin.file:
       path: /home/suhailmsu21/hadoop/hdfs/data
       state: directory
       mode: '0700'
       owner: suhailmsu21


   - name: Modifying hosts file     
     ansible.builtin.copy:
       src: /etc/hosts
       dest: /etc/hosts


   - name: Editing hadoop-env.sh 
     ansible.builtin.lineinfile:
       dest: /home/suhailmsu21/hadoop/etc/hadoop/hadoop-env.sh
       insertafter: EOF
       line: export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
       backup: yes
       owner: suhailmsu21



  post_tasks:
   - name: Editing core.xml File
     
     ansible.builtin.blockinfile:
       dest: /home/suhailmsu21/hadoop/etc/hadoop/core-site.xml
       marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
       insertafter: "<configuration>"
       block: |
         <property>
         <name>fs.defaultFS</name>
         <value>hdfs://amazon_1:9000</value>
         </property>
       backup: yes
       owner: suhailmsu21

   - name: Editing mapred.xml File
     
     ansible.builtin.blockinfile:
       dest: /home/suhailmsu21/hadoop/etc/hadoop/mapred-site.xml
       marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
       insertafter: "<configuration>"
       block: |
         <property>
         <name>mapred.job.tracker</name>
         <value>10.128.0.3:54311</value>
         </property>
         <property>
         <name>mapreduce.framework.name</name>
         <value>yarn</value>
         </property>
         <property>
         <name>yarn.app.mapreduce.am.resource.mb</name>
         <value>2048</value>
         </property>
         <property>
         <name>mapreduce.map.memory.mb</name>
         <value>1024</value>
         </property>
         <property>
         <name>mapreduce.reduce.memory.mb</name>
         <value>1024</value>
         </property>
         <property>
         <name>yarn.app.mapreduce.am.env</name>
         <value>HADOOP_MAPRED_HOME=$HADOOP_MAPRED_HOME</value>
         </property>
         <property>
         <name>mapreduce.map.env</name>
         <value>HADOOP_MAPRED_HOME=$HADOOP_MAPRED_HOME</value>
         </property>
         <property>
         <name>mapreduce.reduce.env</name>
         <value>HADOOP_MAPRED_HOME=$HADOOP_MAPRED_HOME</value>
         </property>
       backup: yes
       owner: suhailmsu21


   - name: Editing hdfs.xml File
     
     ansible.builtin.blockinfile:
       dest: /home/suhailmsu21/hadoop/etc/hadoop/hdfs-site.xml
       marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
       insertafter: "<configuration>"
       block: |
         <property>
         <name>dfs.replication</name>
         <value>3</value>
         </property>
         <property>
         <name>dfs.namenode.name.dir</name>
         <value>file:///usr/local/hadoop/hdfs/data</value>
         </property>
         <property>
         <name>dfs.datanode.data.dir</name>
         <value>file:///usr/local/hadoop/hdfs/data</value>
         </property>
       backup: yes
       owner: suhailmsu21

   - name: Editing yarn-site.xml File
     
     ansible.builtin.blockinfile:
       dest: /home/suhailmsu21/hadoop/etc/hadoop/yarn-site.xml
       marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
       insertafter: "<configuration>"
       block: |
         <property>
         <name>yarn.nodemanager.aux-services</name>
         <value>mapreduce_shuffle</value>
         </property>
         <property>
         <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
         <value>org.apache.hadoop.mapred.ShuffleHandler</value>
         </property>
         <property>
         <name>yarn.resourcemanager.hostname</name>
         <value>10.128.0.3</value>
         </property>
         <property>         
         <name>yarn.nodemanager.resource.memory-mb</name>
         <value>4000</value>
         </property>
         <property>
         <name>yarn.scheduler.maximum-allocation-mb</name>
         <value>4500</value>
         </property>
         <property>
         <name>yarn.scheduler.minimum-allocation-mb</name>
         <value>1024</value>
         </property>
         <property>
         <name>yarn.nodemanager.vmem-check-enabled</name>
         <value>false</value>
         </property>
         </property>
       backup: yes
       owner: suhailmsu21

   - name: Make dir hadoop
     raw: sudo chown suhailmsu21:suhailmsu21 -R hadoop/hdfs/data
   - name: Make dir hadoop2
     raw: chmod 700 hadoop/hdfs/data

   - name: create file masters
     raw: touch /home/suhailmsu21/hadoop/etc/hadoop/masters


   - name: Modifying masters file
     ansible.builtin.blockinfile:
       dest: /home/suhailmsu21/hadoop/etc/hadoop/masters
       insertafter: EOF
       block: |
         10.128.0.3
       backup: yes
       owner: suhailmsu21

   - name: Modifying slaves file
     
     ansible.builtin.blockinfile:
       dest: /home/suhailmsu21/hadoop/etc/hadoop/workers
       insertafter: EOF
       block: |
         10.128.0.4
         10.128.0.6
         10.128.0.8
       backup: yes
       owner: suhailmsu21
   - name: Transferring files to usr/local directory
     raw: mv hadoop /usr/local/hadoop
   - name: Changing permissions of the key
     copy:
       src: /gcp.pem
       dest: /home/suhailmsu21/
       mode: '400'
       owner: suhailmsu21

   - name: Rebooting Machines
     reboot:
